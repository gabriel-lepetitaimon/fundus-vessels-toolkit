{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e0c34b0-70a1-456c-95d7-ca958a69660d",
   "metadata": {},
   "source": [
    "<p style='\n",
    "  color: #3b4045; \n",
    "  text-align: center;\n",
    "  font-weight: bold;\n",
    "  font-family: -apple-system,BlinkMacSystemFont, \"Segoe UI Adjusted\",\"Segoe UI\",\"Liberation Sans\",sans-serif;     font-size: 2.07692308rem; '> \n",
    "    Pretrained Segmentation Model\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80d4566-df33-4463-98d0-cc82b2aa8534",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jppype import Mosaic, vscode_theme\n",
    "\n",
    "from fundus_vessels_toolkit.segment import segment_vessels\n",
    "from fundus_vessels_toolkit.utils.data_io import load_image\n",
    "\n",
    "vscode_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9433049e-7fca-4345-9b27-6595d0032dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the raw fundus image\n",
    "RAW_PATH = \"PATH/TO/FUNDUS/IMAGE\"\n",
    "\n",
    "# Path to a vessel ground truth (for comparison purposes)\n",
    "VESSELS_PATH = \"PATH/TO/VESSEL/GROUND/TRUTH\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b941fe54-0847-4836-9857-cdbcdd0d21e1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Load Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c28d1c89-98c3-470f-be43-8be9c6897fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = load_image(RAW_PATH)\n",
    "\n",
    "vessels_true = load_image(VESSELS_PATH, binarize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9cc4ff-98a0-4640-b454-10a3d540da5c",
   "metadata": {},
   "source": [
    "### Segment vessels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313e15f8-e442-47be-a6c8-aaa9b6a4b854",
   "metadata": {},
   "source": [
    "When called, `fundus_vessels_toolkit.segment.segment_vessels()` will download the weights of a pretrained model, instanciate the model, convert the provided image to the appropriate tensor format, pass it to the model and return the prediction converted back to numpy format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0142945-bf5d-49ca-bdc7-c9cb587d1d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "vessels = segment_vessels(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad92c035-d9a6-445a-b234-68bb0e06790a",
   "metadata": {},
   "source": [
    "For a finner control, the torch pretrained model may also be retreived with `fundus_vessels_toolkit.models.segmentation_model( model_name )`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5184a570",
   "metadata": {},
   "source": [
    "### Precompute fundus mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bcb31a",
   "metadata": {},
   "source": [
    "`segment_vessels()` will compute the mask of the fundus image to clean any prediction from the image background. You can precompute or fine-tune the mask using `fundus_vessels_toolkit.segment.fundus_ROI`.\n",
    "\n",
    "This is especially useful when you want to speed up the vessels segmentation of a series of images with the same fundus mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "299532dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fundus_vessels_toolkit.segment import fundus_ROI\n",
    "\n",
    "mask = fundus_ROI(raw)\n",
    "vessels = segment_vessels(raw, roi_mask=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50640bb1-81ac-46dd-8652-1353cc68cdc1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Display Segmentation Result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0307056-eb43-4b4a-ba5b-022e3e2e7b42",
   "metadata": {},
   "source": [
    "Displays the predicted segmentation and the ground truth side by side.\n",
    "\n",
    "_(The prediction is on the left, the ground truth on the right, the middle show the false positive in green and the false negative in orange.)_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cca0eb9-49f7-44ef-904f-ab18a908396b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m = Mosaic(3, background=raw, cell_height=800, cols_titles=[\"Prediction\", \"Pred vs GT\", \"GT\"])\n",
    "m[0].add_label(vessels, \"vessels\", colormap=\"white\", opacity=0.3)\n",
    "m[0].add_label(1 - mask, \"fundus_ROI\", colormap=\"magenta\", opacity=0.3)\n",
    "m[1].add_label(vessels + 2 * vessels_true, \"vessels\", colormap={3: \"white\", 1: \"green\", 2: \"orange\"})\n",
    "m[2].add_label(vessels_true, \"vessels\", colormap=\"white\", opacity=0.3)\n",
    "\n",
    "m.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
