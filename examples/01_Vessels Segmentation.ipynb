{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e0c34b0-70a1-456c-95d7-ca958a69660d",
   "metadata": {},
   "source": [
    "<p style='\n",
    "  color: #3b4045; \n",
    "  text-align: center;\n",
    "  font-weight: bold;\n",
    "  font-family: -apple-system,BlinkMacSystemFont, \"Segoe UI Adjusted\",\"Segoe UI\",\"Liberation Sans\",sans-serif;     font-size: 2.07692308rem; '> \n",
    "    Pretrained Segmentation Model\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b80d4566-df33-4463-98d0-cc82b2aa8534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ipywidgets import GridspecLayout\n",
    "from jppype import imshow, sync_views\n",
    "\n",
    "from fundus_vessels_toolkit.segment import segment_vessels\n",
    "from fundus_vessels_toolkit.utils.image import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9433049e-7fca-4345-9b27-6595d0032dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the raw fundus image\n",
    "RAW_PATH = \"PATH/TO/FUNDUS/IMAGE\"\n",
    "\n",
    "# Path to a vessel ground truth (for comparison purposes)\n",
    "VESSELS_PATH = \"PATH/TO/VESSEL/GROUND/TRUTH\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b941fe54-0847-4836-9857-cdbcdd0d21e1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Load Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c28d1c89-98c3-470f-be43-8be9c6897fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = load_img(RAW_PATH)\n",
    "vessels_true = load_img(VESSELS_PATH, binarize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9cc4ff-98a0-4640-b454-10a3d540da5c",
   "metadata": {},
   "source": [
    "### Segment vessels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313e15f8-e442-47be-a6c8-aaa9b6a4b854",
   "metadata": {},
   "source": [
    "When called, `fundus_vessels_toolkit.models.segment()` will download the weights of a pretrained model, instanciate the model, convert the provided image to the appropriate tensor format, pass it to the model and return the prediction converted back to numpy format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0142945-bf5d-49ca-bdc7-c9cb587d1d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "vessels = segment_vessels(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3acf0b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 115 ms, sys: 3.05 ms, total: 118 ms\n",
      "Wall time: 117 ms\n",
      "CPU times: user 263 ms, sys: 107 Âµs, total: 263 ms\n",
      "Wall time: 205 ms\n"
     ]
    }
   ],
   "source": [
    "from fundus_vessels_toolkit.seg_to_graph.graph_parsing import fix_skeleton\n",
    "from skimage.morphology import skeletonize as skimage_skeletonize\n",
    "from fundus_vessels_toolkit.seg_to_graph.skeletonization import skeletonize\n",
    "\n",
    "\n",
    "def fast_skeletonize(vessels):\n",
    "    skel = skimage_skeletonize(vessels, method=\"lee\")\n",
    "    return fix_skeleton(skel.astype(bool))\n",
    "\n",
    "\n",
    "%time skeleton = skeletonize(vessels)\n",
    "%time fast_skeleton = fast_skeletonize(vessels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad92c035-d9a6-445a-b234-68bb0e06790a",
   "metadata": {},
   "source": [
    "For a finner control, the torch pretrained model may also be retreived with `fundus_vessels_toolkit.models.segmentation_model( model_name )`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50640bb1-81ac-46dd-8652-1353cc68cdc1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Display Segmentation Result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0307056-eb43-4b4a-ba5b-022e3e2e7b42",
   "metadata": {},
   "source": [
    "Displays the predicted segmentation and the ground truth side by side.\n",
    "\n",
    "_(The prediction is on the left, the ground truth on the right, the middle show the false positive in green and the false negative in orange.)_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cca0eb9-49f7-44ef-904f-ab18a908396b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grid = GridspecLayout(1, 3, height=\"600px\")\n",
    "\n",
    "for i in range(3):\n",
    "    v = imshow(raw)\n",
    "    grid[0, i] = v\n",
    "\n",
    "grid[0, 0].add_label(vessels, \"vessels\", colormap=\"white\", options={\"opacity\": 0.3})\n",
    "grid[0, 1].add_label(vessels + 2 * vessels_true, \"vessels\", colormap={3: \"white\", 1: \"green\", 2: \"orange\"})\n",
    "grid[0, 2].add_label(vessels_true, \"vessels\", colormap=\"white\", options={\"opacity\": 0.3})\n",
    "sync_views(*[grid[0, i] for i in range(3)])\n",
    "\n",
    "grid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
