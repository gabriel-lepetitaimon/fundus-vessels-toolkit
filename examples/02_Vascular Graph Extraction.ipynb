{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82243561-fe7b-47c5-a986-0e91732a452f",
   "metadata": {},
   "source": [
    "<p style='\n",
    "  color: #3b4045; \n",
    "  text-align: center;\n",
    "  font-weight: bold;\n",
    "  font-family: -apple-system,BlinkMacSystemFont, \"Segoe UI Adjusted\",\"Segoe UI\",\"Liberation Sans\",sans-serif;     font-size: 2.07692308rem; '> \n",
    "    Vascular Graph Extraction\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11004821-2c28-4b41-9247-e3889e8dc970",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fundus_vessels_toolkit.seg2graph import RetinalVesselSeg2Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17b99ba6-f60b-453c-b631-19e4c0c88739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the raw fundus image\n",
    "RAW_PATH = \"/home/gaby/These/Data/Fundus/Vessels/FIVES/train/downsampled-1024/1-images/100_A.jpg\"\n",
    "\n",
    "# Path to a vessel ground truth (for comparison purposes)\n",
    "VESSELS_PATH = \"/home/gaby/These/Data/Fundus/Vessels/FIVES/train/downsampled-1024/2-vessels/100_A.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ca5d55-4e9a-4765-8c81-c8f5c35e2d79",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load the raw Image and the Vascular Segmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbf1bc26-3c97-4bbf-afb1-0ed8447d7d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "def load_img(path, binarize=False):\n",
    "    img = cv2.imread(path)\n",
    "    img = img.astype(float) / 255\n",
    "    return img.mean(axis=2) > 0.5 if binarize else img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dc54da-7b9a-42ea-b478-8a025a0828e6",
   "metadata": {},
   "source": [
    "Load image and segmentation mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c28d1c89-98c3-470f-be43-8be9c6897fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = load_img(RAW_PATH)\n",
    "vessels = load_img(VESSELS_PATH, binarize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9f89ce-027f-4a2a-828f-509a79783f15",
   "metadata": {},
   "source": [
    "Perform segmentation using a pretrained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bda3a5cb-01ca-427e-88fe-c5493144fa82",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'timm.models.layers.activations'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfundus_vessels_toolkit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m segment\n\u001b[0;32m----> 2\u001b[0m vessels \u001b[38;5;241m=\u001b[39m \u001b[43msegment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/These/src/Fundus/fundus-vessels-toolkit/lib/fundus_vessels_toolkit/models/segmentation.py:63\u001b[0m, in \u001b[0;36msegment\u001b[0;34m(x, model_name, roi_mask, device)\u001b[0m\n\u001b[1;32m     61\u001b[0m     model \u001b[38;5;241m=\u001b[39m _last_model\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 63\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43msegmentation_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     64\u001b[0m     _last_model \u001b[38;5;241m=\u001b[39m ModelCache(model_name, model)\n\u001b[1;32m     66\u001b[0m raw \u001b[38;5;241m=\u001b[39m x\n",
      "File \u001b[0;32m~/These/src/Fundus/fundus-vessels-toolkit/lib/fundus_vessels_toolkit/models/segmentation.py:114\u001b[0m, in \u001b[0;36msegmentation_model\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mmatch\u001b[39;00m model_name:\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mcase\u001b[39;00m SegmentModel\u001b[38;5;241m.\u001b[39mresnet34:\n\u001b[0;32m--> 114\u001b[0m         \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msegmentation_models_pytorch\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msmp\u001b[39;00m\n\u001b[1;32m    116\u001b[0m         model \u001b[38;5;241m=\u001b[39m smp\u001b[38;5;241m.\u001b[39mUnet(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresnet34\u001b[39m\u001b[38;5;124m\"\u001b[39m, classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    117\u001b[0m         url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://drive.google.com/uc?export=download&id=1IMW3m-tig0Hd0MW46Ula_K61N8I37nHS&confirm=t&uuid=45f08800-5c34-4dd4-98f7-6a9cc338d2e6\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/nnet/lib/python3.10/site-packages/segmentation_models_pytorch/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datasets\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m encoders\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m decoders\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m losses\n",
      "File \u001b[0;32m~/.conda/envs/nnet/lib/python3.10/site-packages/segmentation_models_pytorch/encoders/__init__.py:15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmobilenet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mobilenet_encoders\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mxception\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m xception_encoders\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtimm_efficientnet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m timm_efficientnet_encoders\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtimm_resnest\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m timm_resnest_encoders\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtimm_res2net\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m timm_res2net_encoders\n",
      "File \u001b[0;32m~/.conda/envs/nnet/lib/python3.10/site-packages/segmentation_models_pytorch/encoders/timm_efficientnet.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtimm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mefficientnet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EfficientNet\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtimm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mefficientnet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m decode_arch_def, round_channels, default_cfgs\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtimm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Swish\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EncoderMixin\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_efficientnet_kwargs\u001b[39m(channel_multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, depth_multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, drop_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'timm.models.layers.activations'"
     ]
    }
   ],
   "source": [
    "from fundus_vessels_toolkit.models import segment\n",
    "\n",
    "vessels = segment(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265d5e21-aa88-487f-8dd9-8bbef100d915",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c054972-945d-4cff-a368-0f846c4832cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Skeletonize and Extract Graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68e0d8a-7721-475d-9fc6-561205a5d1d6",
   "metadata": {},
   "source": [
    "All the skeletonization and graph extraction pipeline is accessible through `RetinalVesselSeg2Graph` objects.\n",
    "\n",
    "This object tunes all the parameters of the pipeline according to a single parameter: the maximum vessel diameter.\n",
    "Apriori, a good approximation is a 80th of the image width (13px for a 1024x1024 px image).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3e829d6-fdc7-4071-a1a2-ebe8d42483fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vessel_diameter = raw.shape[1] // 80\n",
    "seg2graph = RetinalVesselSeg2Graph(max_vessel_diameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45688cd-accd-46ce-8c87-990b17941376",
   "metadata": {},
   "source": [
    "To compute the graph extraction you simply need to call the object with a segmentation map:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ca14866-c4c6-4012-b566-1a784a94f8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgraph = seg2graph(vessels)\n",
    "true_vgraph = seg2graph(vessels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe74ea2-e5c9-4049-ac1d-5f1e2c8bdd42",
   "metadata": {},
   "source": [
    "The returned object is a `VascularGraph` which expose all the properties of the extracted graph.\n",
    "\n",
    "- Boolean matrix encoding the connection between branches (rows) and nodes (columns): `vgrapp.branch_by_node`\n",
    "- The y and x position of the nodes: `vgraph.nodes_yx_coord`\n",
    "- The label map of branches: `vgraph.branch_labels_map`\n",
    "\n",
    "This object is also usefull to cast the graph to other representation. For example:\n",
    "\n",
    "- Node Adjacency Matrix: `vgraph.node_adjacency_matrix()`\n",
    "- Branch Adjacency Matrix: `vgraph.branch_adjacency_matrix()`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8928c569-f687-4f1b-bee5-4bb7fd8b9cb0",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353258c7-5528-4f27-95b9-a94e4aac3f24",
   "metadata": {},
   "source": [
    "Lets compare the graph extracted on the predicted segmentation and on the ground truth segmentation side by side!\n",
    "\n",
    "_(The prediction is on the left, the ground truth on the right.)_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cca0eb9-49f7-44ef-904f-ab18a908396b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaddf3734d0c4477b48de649db5385c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridspecLayout(children=(View2D(layout=Layout(grid_area='widget001'), linkedTransformGroup='240cd52691184a64a0â€¦"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from jppype.view2d import imshow, View2D, sync_views\n",
    "from ipywidgets import GridspecLayout\n",
    "\n",
    "\n",
    "def create_view(vessels, vgraph):\n",
    "    v = imshow(raw)\n",
    "    v.add_label(vessels, \"vessel\", \"white\", options={\"opacity\": 0.2})\n",
    "    v[\"vessel graph\"] = vgraph.jppype_layer(edge_map=True)\n",
    "\n",
    "    return v\n",
    "\n",
    "\n",
    "grid = GridspecLayout(1, 2, height=\"650px\")\n",
    "grid[0, 0] = create_view(vessels, vgraph)\n",
    "grid[0, 1] = create_view(vessels, true_vgraph)\n",
    "sync_views(grid[0, 0], grid[0, 1])\n",
    "\n",
    "grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1abeb3-d5e4-4528-95e8-1f15cedc7a59",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b000c2a-8c85-429c-a52f-95dadcb00a67",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Performing only the skeletonization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17ae2f5-368c-40de-bc01-7aa374b317db",
   "metadata": {},
   "source": [
    "The method `RetinalVesselSeg2Graph.seg2adjacency()` actually perform the graph extraction in two steps:\n",
    "\n",
    "- The skeletonization (morphological reduction of the segmentation to the vessels centerline): `seg2graph.skeletonize(vessel_segmentation_map)`\n",
    "- The graph extraction (identification of branches and nodes in the vascular skeleton and connection parsing): `seg2graph.skel2adjacency(vessel_skeleton_map)`.\n",
    "\n",
    "Those method can be called individually, for example to get the result of the skeletonization step only.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea253174-cbea-4ce6-a614-b0e875fbcad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "skeleton = seg2graph.skeletonize(vessels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc478eb-51d7-4638-9cc1-1fe20401404f",
   "metadata": {},
   "source": [
    "You may notice some difference between the skeleton obtained through `seg2graph.skeletonize(vessels)` and by direct call of `seg2graph(vessels)`, because several topological simplification is performed on the latter (merging close nodes, removing small spurs or cycles...).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cd5e07-378a-442c-aab3-33eed70b745c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68f2123d8f8d4f34bfba1b1818cea242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "View2D()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = imshow(raw)\n",
    "v.add_label(vessels, \"vessel\", \"white\", options={\"opacity\": 0.2})\n",
    "v.add_label(skeleton, \"skeleton\", {2: \"white\", 1: \"yellow\", 3: \"red\", 4: \"purple\"})\n",
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddca4a2-3d38-4a87-b79b-dd425e858d45",
   "metadata": {},
   "source": [
    "<br />\n",
    "<hr style=\"width:20%;text-align:center;\"/>\n",
    "\n",
    "Calling `seg2graph.seg2adjacency(vessel_map)` will return the adjacency matrix `adj` which store the graph links between branches (rows) and nodes (columns).\n",
    "\n",
    "If `return_label=True` this method also returns:\n",
    "\n",
    "- the label map of branches where the value of each pixel correspond to its branch id **+ 1** (or 0 if the pixel is not part of the skeleton);\n",
    "- the coordinates of each nodes as a tuple (y, x) where y and x are vectors of length `adj.shape[1]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04f0585-803c-4685-93c9-e163f5152127",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj, branch_labels, node_yx = seg2graph.seg2adjacency(vessels, return_label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ee82f7-b5f0-4780-94a0-c86b95a76fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "732d07683e4d4eb18d8303e4860baa2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "View2D()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = imshow(raw)\n",
    "v.add_label(branch_labels)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea22752-bc4e-496c-8187-a4a7b85f59ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
